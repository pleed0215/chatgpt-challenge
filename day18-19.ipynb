{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-26T10:46:36.118916Z",
     "start_time": "2024-12-26T10:46:35.639884Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "import dotenv\n",
    "from bs4 import BeautifulSoup\n",
    "from langchain.agents import initialize_agent, AgentType\n",
    "from langchain.document_loaders import WikipediaLoader\n",
    "from langchain.schema import SystemMessage\n",
    "from langchain.tools import BaseTool\n",
    "from pydantic import Field\n",
    "from pydantic.main import BaseModel\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "from duckduckgo_search import DDGS\n",
    "assignment_query = \"Research about the XZ backdoor\""
   ],
   "id": "9f89f0b8907fa921",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-26T10:46:36.182862Z",
     "start_time": "2024-12-26T10:46:36.144355Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "144bfe9ecdc87afc",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-26T10:46:36.239513Z",
     "start_time": "2024-12-26T10:46:36.233348Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain.tools import BaseTool\n",
    "class WikipediaSearchToolArgsSchema(BaseModel):\n",
    "    query: str = Field(\"The query for information\")\n",
    "\n",
    "class WikipediaSearchTool(BaseTool):\n",
    "    name:str = \"WikipediaSearchTool\"\n",
    "    description:str = \"\"\"\n",
    "    Search Wikipedia, get 3 important keywords from it, and returns as python array of keywords\n",
    "    \"\"\"\n",
    "    def _run(self, query, **kwargs):\n",
    "        wiki = WikipediaLoader(\n",
    "            query=query,\n",
    "        )\n",
    "        return wiki"
   ],
   "id": "48fcad2219445e12",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-26T10:46:36.257458Z",
     "start_time": "2024-12-26T10:46:36.250268Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from typing import Type, TypedDict\n",
    "\n",
    "\n",
    "class DuckDuckGoToolArgsSchema(BaseModel):\n",
    "    queries: list[str] = Field(description=\"The queries search urls\")\n",
    "\n",
    "class DuckDuckGoSearchTool(BaseTool):\n",
    "    name:str = \"DuckDuckGoSearchTool\"\n",
    "    description:str = \"\"\"\n",
    "    This tool send queries to Duck Duck Go Search engine to get link associated with the query.\n",
    "    \"\"\"\n",
    "    args_schema:Type[DuckDuckGoToolArgsSchema] = DuckDuckGoToolArgsSchema\n",
    "    def _run(self, queries: list[str], **kwargs):\n",
    "        ddgs = DDGS()\n",
    "        result =  [ddgs.text(query, region='ko-KR', max_results=2)for query in queries]\n",
    "        return result"
   ],
   "id": "955d9c7bbaaf4ef2",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-26T10:46:36.274963Z",
     "start_time": "2024-12-26T10:46:36.267465Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from typing_extensions import TypedDict\n",
    "import requests\n",
    "class Info(TypedDict):\n",
    "    title: str\n",
    "    href: str\n",
    "class ScrapingWebsitesToolArgsSchema(BaseModel):\n",
    "    infos: list[Info] = Field(description=\"Arrays of information that has title and href.\")\n",
    "class ScrapingWebsitesTool(BaseTool):\n",
    "    name: str = \"ScrapingWebsitesTool\"\n",
    "    description:str = \"DuckDuckGoSearchTool will give href to this tool and then this tools will scape the website. \"\n",
    "    args_schema:Type[ScrapingWebsitesToolArgsSchema] = ScrapingWebsitesToolArgsSchema\n",
    "    def _run(self, infos:list[Info], **kwargs):\n",
    "        results = []\n",
    "        for info in infos:\n",
    "            res = requests.get(info['href'], verify=False)\n",
    "            soup = BeautifulSoup(res.content, \"html.parser\")\n",
    "            results.append({\n",
    "                'title': info['title'],\n",
    "                'href': info['href'],\n",
    "                'text': soup.get_text(strip=True).replace(\"\\n\\n\", \"\\n\"),})\n",
    "        return results"
   ],
   "id": "72a6713bdbbb6fbc",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-26T10:46:36.300433Z",
     "start_time": "2024-12-26T10:46:36.283959Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class SavingInfo(TypedDict):\n",
    "    title: str\n",
    "    href: str\n",
    "    text: str\n",
    "class SavingToFileToolArgsSchema(BaseModel):\n",
    "    infos: list[SavingInfo] = Field(description=\"Arrays of dictionary that has title, href, and text as key.\")\n",
    "class SavingToFileTool(BaseTool):\n",
    "    name:str = \"SavingToFileTool\"\n",
    "    description:str = \"This tool will save all information from Scarping tool information\"\n",
    "\n",
    "    def _run(self, infos:list[SavingInfo], **kwargs):\n",
    "        import csv\n",
    "        with open(\"./information.txt\", \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow([\"title\", \"href\", \"text\"])\n",
    "            for info in infos:\n",
    "                title = info.get(\"title\", \"N/A\")\n",
    "                href = info.get(\"href\", \"N/A\")\n",
    "                text = info.get(\"text\", \"N/A\")\n",
    "                writer.writerow([title, href, text])\n"
   ],
   "id": "c6a1b6b7673d6e2e",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-26T10:47:15.076672Z",
     "start_time": "2024-12-26T10:46:36.327334Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.agents import AgentType\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\",\n",
    ")\n",
    "agent = initialize_agent(\n",
    "    llm=llm,\n",
    "    agent=AgentType.OPENAI_FUNCTIONS,\n",
    "    tools=[\n",
    "        WikipediaSearchTool(),\n",
    "        DuckDuckGoSearchTool(),\n",
    "        ScrapingWebsitesTool(),\n",
    "        SavingToFileTool(),\n",
    "    ],\n",
    "    # verbose=True,\n",
    "    handle_parsing_errors=True,\n",
    "    agent_kwargs={\n",
    "        \"system_message\": SystemMessage(content=\"\"\"\n",
    "        You are a good research AI for collection information.\n",
    "        You will collect information from Wikipedia. Summary it and make array for searching web href from DuckDuckGo.\n",
    "        Next, you will scrape information from those urls above hrefs using ScrapingWebsitesTool.\n",
    "        And ScarpingWebsitesTool's result will be send to SavingToFileTool for saving file information.\n",
    "        Beware that before send information from ScrapingWebsiteTool to SavingFileTool you must summary the text that each array of dictionary has. Good luck.\n",
    "        \"\"\")\n",
    "    }\n",
    ")\n",
    "result = agent.invoke(assignment_query)\n",
    "result"
   ],
   "id": "5a94ed24ec3efbb4",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cg/f9fd4h8n2snc_f1sq9lfsgqr0000gn/T/ipykernel_59946/1729189740.py:3: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import ChatOpenAI``.\n",
      "  llm = ChatOpenAI(\n",
      "/var/folders/cg/f9fd4h8n2snc_f1sq9lfsgqr0000gn/T/ipykernel_59946/1729189740.py:6: LangChainDeprecationWarning: LangChain agents will continue to be supported, but it is recommended for new use cases to be built with LangGraph. LangGraph offers a more flexible and full-featured framework for building agents, including support for tool-calling, persistence of state, and human-in-the-loop workflows. See LangGraph documentation for more details: https://langchain-ai.github.io/langgraph/. Refer here for its pre-built ReAct agent: https://langchain-ai.github.io/langgraph/how-tos/create-react-agent/\n",
      "  agent = initialize_agent(\n",
      "/Users/pleed0215/Documents/mystudy/python/chatgpt-challenge/venv/lib/python3.10/site-packages/urllib3/connectionpool.py:1056: InsecureRequestWarning: Unverified HTTPS request is being made to host 'en.wikipedia.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "/Users/pleed0215/Documents/mystudy/python/chatgpt-challenge/venv/lib/python3.10/site-packages/urllib3/connectionpool.py:1056: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.wired.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "/Users/pleed0215/Documents/mystudy/python/chatgpt-challenge/venv/lib/python3.10/site-packages/urllib3/connectionpool.py:1056: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arstechnica.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'Research about the XZ backdoor',\n",
       " 'output': 'I have gathered information about the XZ backdoor, a significant cybersecurity incident involving the XZ Utils software. Here’s a summary of the findings:\\n\\n### Summary of the XZ Backdoor Incident\\n1. **Discovery**: In February 2024, a malicious backdoor was embedded in the Linux build of the XZ utility, specifically within versions 5.6.0 and 5.6.1 of the liblzma library. It was introduced by an individual or group using the name \"Jia Tan.\"\\n   \\n2. **Functionality**: The backdoor allowed attackers possessing a specific Ed448 private key to execute remote code on affected Linux systems, potentially compromising the entire system’s security.\\n\\n3. **Detection**: The backdoor was discovered by software developer Andres Freund while he was investigating performance issues related to SSH connections on Debian systems. The public disclosure occurred on March 29, 2024.\\n\\n4. **Impact**: The sophistication of the backdoor was highlighted by its stealthy integration into a widely used open-source utility, raising alarms about software supply chain security. It was nearly merged into major Linux distributions like Debian and Red Hat.\\n\\n5. **Response**: Following the discovery, various Linux distributions reverted to earlier, uncompromised versions of the affected software, and security advisories were issued to mitigate potential risks.\\n\\n### Relevant Links\\n- [XZ Utils Backdoor - Wikipedia](https://en.wikipedia.org/wiki/XZ_Utils_backdoor)\\n- [The XZ Backdoor: Everything You Need to Know - WIRED](https://www.wired.com/story/xz-backdoor-everything-you-need-to-know/)\\n- [What We Know About the XZ Utils Backdoor That Almost Infected the World - Ars Technica](https://arstechnica.com/security/2024/04/what-we-know-about-the-xz-utils-backdoor-that-almost-infected-the-world/)\\n\\nThe incident serves as a critical reminder of the vulnerabilities in open-source software development and the importance of robust security practices in the software supply chain.'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-26T10:47:15.100341Z",
     "start_time": "2024-12-26T10:47:15.098690Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "bf6cb5ac225f7b0c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-26T10:47:15.113636Z",
     "start_time": "2024-12-26T10:47:15.112219Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "8d767ccc9dd3ccd3",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 5,
 "nbformat_minor": 9
}
