{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-13T05:03:15.241908Z",
     "start_time": "2024-12-13T05:03:15.234906Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Stuff Documents 체인을 사용하여 완전한 RAG 파이프라인을 구현하세요.\n",
    "# 체인을 수동으로 구현해야 합니다.\n",
    "# 체인에 ConversationBufferMemory를 부여합니다.\n",
    "# 이 문서를 사용하여 RAG를 수행하세요: https://gist.github.com/serranoarevalo/5acf755c2b8d83f1707ef266b82ea223\n",
    "# 체인에 다음 질문을 합니다:\n",
    "# Aaronson 은 유죄인가요?\n",
    "# 그가 테이블에 어떤 메시지를 썼나요?\n",
    "# Julia 는 누구인가요?\n",
    "import dotenv\n",
    "dotenv.load_dotenv()"
   ],
   "id": "bfcfc8aba0747fc8",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-13T05:03:15.463781Z",
     "start_time": "2024-12-13T05:03:15.270989Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain.document_loaders import TextLoader\n",
    "text_loader = TextLoader('./documents/document.txt')"
   ],
   "id": "70946f1dfde0b0cb",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-13T05:03:15.636721Z",
     "start_time": "2024-12-13T05:03:15.501599Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    separators=[\n",
    "        '\\n\\n','\\n'\n",
    "    ],\n",
    "    chunk_size=600,\n",
    "    chunk_overlap=100,\n",
    ")\n",
    "docs = text_loader.load_and_split(text_splitter=text_splitter)"
   ],
   "id": "7f30aadced912f7d",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-13T05:03:15.751904Z",
     "start_time": "2024-12-13T05:03:15.640531Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain.embeddings import OpenAIEmbeddings, CacheBackedEmbeddings\n",
    "from langchain.storage import LocalFileStore\n",
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "CACHE_DIR = './.cache'\n",
    "embeddings = OpenAIEmbeddings()\n",
    "cache_store = LocalFileStore(CACHE_DIR)\n",
    "cache_embeddings = CacheBackedEmbeddings.from_bytes_store(embeddings, cache_store)\n",
    "vector_store = FAISS.from_documents(docs, cache_embeddings)"
   ],
   "id": "a3159dbe7d7cb6a5",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-13T05:03:15.959668Z",
     "start_time": "2024-12-13T05:03:15.755792Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "memory = ConversationBufferMemory(\n",
    "    memory_key='chat_history',\n",
    "    return_messages=True,\n",
    ")\n"
   ],
   "id": "bf99c59bff414c79",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-13T05:03:15.966469Z",
     "start_time": "2024-12-13T05:03:15.963579Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    ('system', \"\"\"\n",
    "    You are good at replying users questions based on below context.\\n\\n\n",
    "\n",
    "    context: {context},\n",
    "    ------\n",
    "    \"\"\"),\n",
    "    MessagesPlaceholder(variable_name='chat_history'),\n",
    "    ('human', '{question}'),\n",
    "])\n",
    "llm = ChatOpenAI(\n",
    "    model='gpt-3.5-turbo',\n",
    "    temperature=0.1,\n",
    ")\n",
    "questions = [\n",
    "   \"Is Aaronson guilty?\",\n",
    "   \"What messages did he write on the table?\",\n",
    "   \"Who is Julia?\",\n",
    "]"
   ],
   "id": "a658465877902ced",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-13T05:03:15.973229Z",
     "start_time": "2024-12-13T05:03:15.970713Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain.schema.runnable import RunnablePassthrough, RunnableLambda\n",
    "chain = {\"question\": RunnablePassthrough(), \"context\": vector_store.as_retriever(), 'chat_history': RunnableLambda(lambda _: memory.load_memory_variables({})['chat_history'])}| prompt | llm\n"
   ],
   "id": "cb189663f2a48766",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-13T05:03:19.798793Z",
     "start_time": "2024-12-13T05:03:15.978135Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def ask_something(question:str):\n",
    "    print(question)\n",
    "    print('----------')\n",
    "    answer = chain.invoke(question)\n",
    "    print(answer.content)\n",
    "    print('----------\\n')\n",
    "    memory.save_context(\n",
    "        inputs={\n",
    "            'human': question,\n",
    "        },\n",
    "        outputs={\n",
    "            'ai': answer.content,\n",
    "        }\n",
    "    )\n",
    "for q in questions:\n",
    "    ask_something(q)"
   ],
   "id": "b35040bda823e646",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Aaronson guilty?\n",
      "----------\n",
      "According to the text, Jones, Aaronson, and Rutherford were guilty of the crimes they were charged with.\n",
      "----------\n",
      "\n",
      "What messages did he write on the table?\n",
      "----------\n",
      "He wrote the following messages on the table:\n",
      "\n",
      "1. FREEDOM IS SLAVERY\n",
      "2. TWO AND TWO MAKE FIVE\n",
      "3. GOD IS POWER\n",
      "----------\n",
      "\n",
      "Who is Julia?\n",
      "----------\n",
      "Julia is a character in the text who is associated with the protagonist. She is someone whom the protagonist loves and cares for deeply.\n",
      "----------\n",
      "\n"
     ]
    }
   ],
   "execution_count": 8
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 5,
 "nbformat_minor": 9
}
